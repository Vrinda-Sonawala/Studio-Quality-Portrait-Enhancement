{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff7a881",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from google.colab.patches import cv2_imshow\n",
    "import os\n",
    "\n",
    "def studio_quality_enhancer(image_path):\n",
    "    # 1. Load Image\n",
    "    if not os.path.exists(image_path):\n",
    "        print(\"Error: Image not found.\")\n",
    "        return None, None\n",
    "\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        return None, None\n",
    "        \n",
    "    h, w = img.shape[:2]\n",
    "\n",
    "    # 2. SUBJECT SEGMENTATION \n",
    "    # Using a fixed rectangle for subject focus\n",
    "    mask = np.zeros(img.shape[:2], np.uint8)\n",
    "    rect = (int(w*0.05), int(h*0.05), int(w*0.9), int(h*0.9))\n",
    "    \n",
    "    bgdModel = np.zeros((1, 65), np.float64)\n",
    "    fgdModel = np.zeros((1, 65), np.float64)\n",
    "\n",
    "    # GrabCut isolates the human from background\n",
    "    cv2.grabCut(img, mask, rect, bgdModel, fgdModel, 3, cv2.GC_INIT_WITH_RECT)\n",
    "    \n",
    "    # Create mask: 1 for foreground, 0 for background\n",
    "    mask2 = np.where((mask == 2) | (mask == 0), 0, 1).astype('uint8')\n",
    "    mask_3d = cv2.merge([mask2, mask2, mask2])\n",
    "\n",
    "    # -- 3. BACKGROUND BLUR (PORTRAIT EFFECT) --\n",
    "    blurred_bg = cv2.GaussianBlur(img, (99, 99), 0)\n",
    "    # Combine sharp subject and blurred background\n",
    "    bokeh_img = np.where(mask_3d == 1, img, blurred_bg)\n",
    "\n",
    "    # -- 4. FACE CLARITY & SHARPNESS--\n",
    "    sharp_img = cv2.detailEnhance(bokeh_img, sigma_s=10, sigma_r=0.15)\n",
    "\n",
    "    # -- 5. STUDIO LIGHTING (CLAHE) --\n",
    "\n",
    "    lab = cv2.cvtColor(sharp_img, cv2.COLOR_BGR2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.5, tileGridSize=(8,8))\n",
    "    l = clahe.apply(l)\n",
    "    studio_light = cv2.cvtColor(cv2.merge((l, a, b)), cv2.COLOR_LAB2BGR)\n",
    "\n",
    "    # -- 6. SKIN TEXTURE PRESERVATION (Bilateral Filter)--\n",
    "    final_output = cv2.bilateralFilter(studio_light, 9, 75, 75)\n",
    "\n",
    "    return img, final_output\n",
    "\n",
    "# ------ RUNNING THE PIPELINE ------\n",
    "# Here file is uploaded as 'myphoto.jpg'\n",
    "target = '/content/myphoto.jpg'\n",
    "\n",
    "if os.path.exists(target):\n",
    "    original, result = studio_quality_enhancer(target)\n",
    "    \n",
    "    if result is not None:\n",
    "        print(\"SUCCESS: Studio-quality portrait generated:)\")\n",
    "        \n",
    "        # Display side-by-side\n",
    "        h_disp, w_disp = 600, 450\n",
    "        comparison = np.hstack((cv2.resize(original, (w_disp, h_disp)), \n",
    "                                cv2.resize(result, (w_disp, h_disp))))\n",
    "        cv2_imshow(comparison)\n",
    "else:\n",
    "    print(\"Upload your image first!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
